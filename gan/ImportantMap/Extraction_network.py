import sys
import numpy as np
from numpy import int32, zeros_like
import tensorflow as tf
from tensorflow.keras import layers
import os
import time
import matplotlib.pyplot as plt

# choose DataLoad.initialize for different image size
# change size in ImportantMapEncoder and ImportantMapDecoder

_HEIGHT=1024
_WIDTH=2048
_CHANNAL=3
L=16    #compression rate

raw_image_dataset = tf.data.TFRecordDataset('dataset\city\cityscape.tfrecords')
# Create a dictionary describing the features.
image_feature_description = {
    'image_left': tf.io.FixedLenFeature([], tf.string),
    'segmentation_label': tf.io.FixedLenFeature([],tf.string)
}

def _parse_image_function(example_proto):
   # Parse the input tf.Example proto using the dictionary above.
    dataset=tf.io.parse_single_example(example_proto, image_feature_description)
    image_png=tf.io.decode_png(dataset['image_left'])
    map_png=tf.io.decode_png(dataset['segmentation_label'])
    image_png=tf.image.convert_image_dtype(image_png,dtype=tf.float32)
    image_png=tf.image.resize(image_png,[_HEIGHT,_WIDTH])
    dataset['image_left']=2*image_png-1
    return dataset

parsed_image_dataset = raw_image_dataset.map(_parse_image_function)
#parsed_image_dataset=parsed_image_dataset.take(8)
parsed_image_dataset=parsed_image_dataset.shuffle(1).batch(1)



"""
for example in dataset:
    image=example["image_left"]
    semantic_map=example["segmentation_label"]
    plt.figure()
    plt.subplot(1,2,1)
    plt.imshow((image[0,:,:,:]+1)/2)
    plt.subplot(1,2,2)
    plt.imshow((semantic_map[0,:,:,:]+1)/2)

plt.show()
"""

class Quantizer(layers.Layer):
    """
    Equation (4) in paper implemented with L = 16 quantized values
    Elementwise function

    Input: An importance map of shape (N,1,h,w) with each element
            having a value between (0-1) representing importance probability

    Output: A tensor of the same shape with each element quantized to
            L different integer values from 0 to (L-1)
    """
    def __init__(self,L):
        super(Quantizer,self).__init__()
        self.L=L
    @tf.custom_gradient
    def call(self,input):
        def grad(upstream):
            # print("in Quan grad",upstream.shape)
            return upstream
        for l in range(self.L):
            val=l*tf.ones_like(input)
            input=tf.where((input >= l/self.L)&(input < (l+1)/self.L),x=val,y=input)
        return input,grad

class Mask(layers.Layer):
    """
    Equation (6) and (7) in paper. This mask will be element-wise
    multiplied with the binary feature map generated by the encoder.

    Input:  A quantized importance map of shape (N,1,h,w)
            with L different integer values from 0 to (L-1)

    Output: A 3-D mask of dimensions (N,64,h,w) filled with
            sequential 1s and 0s

    """
    def __init__(self,L):
        super(Mask,self).__init__()
        self.L=L
    @tf.custom_gradient
    def call(self,input):

        def grad(upstream):
            upstream_singlelayer=upstream[:,:,:,0]
            Ls=self.L*tf.ones_like(upstream_singlelayer,dtype=tf.float32)
            zeros=tf.zeros_like(upstream_singlelayer,tf.float32)
            cond=(self.L*upstream_singlelayer-1<=tf.math.ceil(channel*self.L/channels))&(tf.math.ceil(channel*self.L/channels)<=self.L*upstream_singlelayer+2)
            return tf.where(cond,Ls,zeros)

        N,H,W,C=input.shape
        # TODO: channels value depends on the channel of binart feature map
        # passing the parameter into call() will be a Tensor
        # channels.type will be a Tensor but expected int
        # TypeError: 'Tensor' object cannot be interpreted as an integer
        channels=64
        zeros=tf.zeros_like(input,dtype=tf.float32)
        ones=tf.ones_like(input,dtype=tf.float32)
        for channel in range(channels):
            mask_singlelayer=tf.where(tf.math.ceil(channel*self.L/channels)<tf.cast(self.L*input,dtype=tf.float32),x=ones,y=zeros)
            if channel==0:
                mask=mask_singlelayer
            else:
                mask=tf.concat([mask,mask_singlelayer],axis=-1)
        return mask,grad

class Binarizer(layers.Layer):
    def __init__(self,threshold):
        super(Binarizer,self).__init__()
        self.threshold=threshold
    # TODO: see equation (1)(2)(3) in the paper
    # do nothing while applying equation (2) ? no binarizer ?   
    @tf.custom_gradient
    def call(self,input):
        def grad(upstream):
            return upstream
        zeros=tf.zeros_like(input)
        ones=tf.ones_like(input)
        return tf.where(input<self.threshold,x=zeros,y=ones),grad


THRESHOLD=0.5
QUAN=Quantizer(L)
MASK=Mask(L)
BINA=Binarizer(THRESHOLD)

class ImportantMapEncoder(tf.keras.Model):
    def __init__(self):
        super(ImportantMapEncoder,self).__init__(name='ImportantMapEncoder')
        
        input=tf.keras.Input(shape=(_HEIGHT,_WIDTH,_CHANNAL))
        #input=tf.keras.Input(shape=(64,128,3))
        #input=tf.keras.Input(shape=(512,512,3))
        # conv1
        x=layers.ZeroPadding2D(padding=(2,2))(input)
        x=layers.Conv2D(128,kernel_size=(8,8),strides=(4,4),padding='valid')(x)
        x=layers.ReLU()(x)
        x_origin=x
        # blk1_branch2b
        x=layers.Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk1_branch2c
        x=layers.Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk1
        x=layers.Add()([x_origin,x])
        x=layers.ReLU()(x)
        # conv2
        x=layers.ZeroPadding2D(padding=(1,1))(x)
        x=layers.Conv2D(256,kernel_size=(4,4),strides=(2,2),padding='valid')(x)
        x=layers.ReLU()(x)
        x_origin=x
        # blk2_branch2b
        x=layers.Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk2_branch2c
        x=layers.Conv2D(256,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk2
        x=layers.Add()([x_origin,x])
        x=layers.ReLU()(x)
        # conv3
        x=layers.ZeroPadding2D(padding=(1,1))(x)
        x=layers.Conv2D(256,kernel_size=(3,3),strides=(1,1),padding='valid')(x)
        x=layers.ReLU()(x)
        x_origin=x
        # blk3_branch2b
        x=layers.Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk3_branch2b
        x=layers.Conv2D(256,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk3
        x=layers.Add()([x_origin,x])
        x=layers.ReLU()(x)
        
        mgdata=x
        imap=x
        # conv4
        mgdata=layers.Conv2D(64,kernel_size=(1,1),strides=(1,1),padding='valid')(mgdata)
        mgdata=tf.keras.activations.sigmoid(mgdata)
        # imp_conv1
        imap=layers.Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='same')(imap)
        imap=layers.ReLU()(imap)
        # imp_conv2
        imap=layers.Conv2D(1,kernel_size=(1,1),strides=(1,1),padding='valid')(imap)
        imap=tf.keras.activations.sigmoid(imap)
        # version 1       
        binary_feature_map=BINA(mgdata)
        channels=mgdata.shape[-1]
        print("channels=",channels)
        mask=MASK(QUAN(imap))
        output=layers.Multiply()([binary_feature_map,mask])
        
        # version 2 
        #binary_feature_map=BINA(mgdata)
        #output=layers.Multiply()([binary_feature_map,imap])
        # version 3
        #output=layers.Multiply()([imap,mgdata])

        self.model=tf.keras.Model(inputs=input,outputs=output)

    def bulid(self,input_shape):
        pass

    def call(self,input):
        """
        Project channels onto space w/ dimension C
        Feature maps have dimension W/16 x H/16 x C 
        """
        output=self.model(input)
        return output

"""
IMPEnc=ImportantMapEncoder()
IMPEnc.model.summary()
tf.keras.utils.plot_model(IMPEnc.model,'./modelFigure/IMPEncoder.png',show_shapes=True)
"""

class DepthToSpace(tf.keras.Model):

    """
    A class used by the decoder while regenerating the image that moves values
    from the depth dimension to the height and width dimensions (spatial)

    Input: A tensor of size [N,C,H,W]
    Returns: A tensor of size [N,C/(block_size*block_size),H*block_size,W*block_size]

    Parameters
    ----------
    block_size: An int that is greater than 2. It decide

    Extra
    -----
    https://www.tensorflow.org/api_docs/python/tf/nn/depth_to_space
    """

    def __init__(self, block_size):
        super().__init__()
        self.bs = block_size

    def forward(self, x):
        N, C, H, W = x.size()
        x = x.view(N, self.bs, self.bs, C // (self.bs ** 2), H, W)
        x = x.permute(0, 3, 4, 1, 5, 2).contiguous()
        x = x.view(N, C // (self.bs ** 2), H * self.bs, W * self.bs)
        return x

class ImportantMapDecoder(tf.keras.Model):
    def __init__(self):
        super(ImportantMapDecoder,self).__init__(name='ImportantMapDecoder')
        
        input=tf.keras.Input(shape=(_HEIGHT//8,_WIDTH//8,64))
        #input=tf.keras.Input(shape=(8,16,64))
        #input=tf.keras.Input(shape=(64,64,64))
        # inv_conv1
        x=layers.ZeroPadding2D(padding=(1,1))(input)
        x=layers.Conv2D(512,kernel_size=(3,3),strides=(1,1),padding='valid')(x)
        x=layers.ReLU()(x)
        x_origin=x
        # blk4_branch2b
        x=layers.Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk4_branch2c
        x=layers.Conv2D(512,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk4
        x=layers.Add()([x_origin,x])
        x=layers.ReLU()(x)
        # inv_conv2
        x=layers.ZeroPadding2D(padding=(1,1))(x)
        x=layers.Conv2D(512,kernel_size=(3,3),strides=(1,1),padding='valid')(x)
        x=layers.ReLU()(x)
        x_origin=x
        # blk5_branch2b
        x=layers.Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk5_branch2c
        x=layers.Conv2D(512,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk5
        x=layers.Add()([x_origin,x])
        x=layers.ReLU()(x)

        x=tf.nn.depth_to_space(x,2)

        # inv_conv3
        x=layers.ZeroPadding2D(padding=(1,1))(x)
        x=layers.Conv2D(256,kernel_size=(3,3),strides=(1,1),padding='valid')(x)
        x=layers.ReLU()(x)
        x_origin=x
        # blk6_branch2b
        x=layers.Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk6_branch2b
        x=layers.Conv2D(256,kernel_size=(3,3),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)
        # blk6
        x=layers.Add()([x_origin,x])
        x=layers.ReLU()(x)
        
        x=tf.nn.depth_to_space(x,4)

        # inv_conv4
        x=layers.Conv2D(32,kernel_size=(1,1),strides=(1,1),padding='same')(x)
        x=layers.ReLU()(x)

        output=layers.Conv2D(3,kernel_size=(1,1),strides=(1,1),padding='valid')(x)

        #output=layers.Multiply()([mgdata,imap])

        self.model=tf.keras.Model(inputs=input,outputs=output)

    def bulid(self,input_shape):
        pass

    def call(self,input):
        """
        Project channels onto space w/ dimension C
        Feature maps have dimension W/16 x H/16 x C 
        """
        genImg=self.model(input)
        return genImg

"""
IMPDec=ImportantMapDecoder()
IMPDec.model.summary()
tf.keras.utils.plot_model(IMPDec.model,'./modelFigure/IMPDecoder.png',show_shapes=True)
"""
ENC=ImportantMapEncoder()
DEC=ImportantMapDecoder()
"""
ENC.model.summary()
DEC.model.summary()
"""
optimizer_ENC=tf.keras.optimizers.Adam(0.0002)
optimizer_DEC=tf.keras.optimizers.Adam(0.0002)
MSE=tf.keras.losses.MeanSquaredError()

getImpMap_model=tf.keras.Model(inputs=ENC.model.input,outputs=ENC.model.get_layer(name='tf.math.sigmoid_1').output)
#getImpMap_model.summary()

def getLoss(srcImg,desImg,impMap):
    # equation (8) in the paper
    # distortion loss + rate loss
    # TODO: gamma and threshold
    # gamma range [0.0001,0.2]
    # threshold = r_0*h*w for n=64 and 0.5*r_0*h*w for n=128, 
    # in which r_0 is the wanted compression rate represented with bpp
    impMap=tf.squeeze(input=impMap,axis=[0])
    L_D=MSE(srcImg,desImg)
    L_R=tf.math.reduce_sum(impMap)
    gamma=0
    loss_threshold=0
    if L_R > loss_threshold :
        L_R=L_R-loss_threshold
    else:
        L_R=0
    return L_D+gamma*L_R

losses=[]

def train_step(srcImg):

    with tf.GradientTape() as enc_tape,tf.GradientTape() as dec_tape:
        midResult=ENC(srcImg)
        desImg=DEC(midResult)
        impMap=getImpMap_model(srcImg)
        loss=getLoss(srcImg,desImg,impMap)
        losses.append(loss)

    gradient_of_encoder=enc_tape.gradient(loss,ENC.trainable_variables)
    gradient_of_decoder=dec_tape.gradient(loss,DEC.trainable_variables)
    optimizer_ENC.apply_gradients(zip(gradient_of_encoder,ENC.trainable_variables))
    optimizer_DEC.apply_gradients(zip(gradient_of_decoder,DEC.trainable_variables))
   

def getImpMap(epoch,dataset):
    for index,example in enumerate(dataset):
        img=example["image_left"]
        midResult=ENC(img)
        desImg=DEC(midResult)
        impMap=getImpMap_model.predict(img)

        desImg=tf.squeeze(input=desImg,axis=[0])
        desImg=(desImg+1)/2
        desImg=tf.math.multiply(desImg,255)
        desImg=tf.cast(desImg,dtype=tf.uint8)
        desImg=tf.image.encode_png(desImg)
        with tf.io.gfile.GFile('./SemCom/importantMap/imgs/city_GenImg_of_{}_epoch{:04d}.png'.format(index,epoch), 'wb') as file:
            file.write(desImg.numpy())

        impMap=tf.squeeze(input=impMap,axis=[0])
        plt.axis("off")
        # 如果dpi=300，那么图像大小=height*width 
        plt.figure(figsize=(_HEIGHT/8,_WIDTH/8),dpi=96)
        plt.gca().xaxis.set_major_locator(plt.NullLocator()) 
        plt.gca().yaxis.set_major_locator(plt.NullLocator()) 
        plt.subplots_adjust(top=1,bottom=0,left=0,right=1,hspace=0,wspace=0) 
        plt.margins(0,0)
        plt.imshow(impMap)
        plt.savefig('./SemCom/importantMap/imgs/city_ImpMap_of_{}_epoch{:04d}.png'.format(index,epoch))
        plt.close()


def train(dataset,epochs):
    for epoch in range(epochs):
        start=time.time()
        for example in dataset:
            img=example["image_left"]
            train_step(img)
        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))
        if epoch%50==0:
            getImpMap(epoch,parsed_image_dataset)


EPOCH=1001
train(parsed_image_dataset,EPOCH)

print("ok")

"""
def save_images(input):
    plt.savefig('./img/image_at_epoch_{:04d}.png'.format(epoch))
    print('image_at_epoch_{:04d} have saved'.format(epoch))
"""





print("ok again")



"""
checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")

model_dir = './modelSave'
#getImpMap_model.save("save_getImpMap_model")
tf.saved_model.save(getImpMap_model, os.path.join(model_dir, 'importantMapModel'))
print("model saved")
"""